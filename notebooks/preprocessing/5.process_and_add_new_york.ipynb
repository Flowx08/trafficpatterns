{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f3885ffc",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "30992c83",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e354355",
   "metadata": {},
   "source": [
    "# Loads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "21ee16f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bike = pd.read_csv('Material/nyc_bicycle.csv')\n",
    "df_stations = pd.read_csv('Material/nyc_stations.csv')\n",
    "df_weather = pd.read_csv('Material/nyc_weather.csv')\n",
    "df_traffic = pd.read_csv('Material/nyc_traffic.csv')\n",
    "mighty_df = pd.read_csv('Material/data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfafd30e",
   "metadata": {},
   "source": [
    "# Preprocessing nyc count data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "795a72b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add long lat from df_stations \n",
    "counts_with_all = df_bike.merge(df_stations, how='outer', on='site')\n",
    "\n",
    "# Take only valuable columns\n",
    "counts_with_all = counts_with_all[['longitude','latitude', 'date', 'counts']]\n",
    "\n",
    "# add several columns for time and change the time column type to satetime\n",
    "counts_with_all['time']  = pd.to_datetime(counts_with_all['date'], format='%m/%d/%Y %I:%M:%S %p')\n",
    "counts_with_all['hour'] = counts_with_all['time'].dt.hour\n",
    "counts_with_all['min'] = counts_with_all['time'].dt.minute\n",
    "\n",
    "# Reduce granularity of the observations\n",
    "counts_with_all = counts_with_all[counts_with_all['min']==0]\n",
    "\n",
    "# select necessary columns\n",
    "counts_with_all = counts_with_all[['longitude','latitude', 'time','hour', 'counts']]\n",
    "counts_with_all.columns = ['longitude','latitude', 'time','hour', 'count']\n",
    "\n",
    "# Indicate that those columns are for bucycle data\n",
    "counts_with_all.insert(4, 'type', 'bicycle')\n",
    "df_weather['time'] =  pd.to_datetime(df_weather['time'])\n",
    "\n",
    "# Merge nyc bike counts and weatherr\n",
    "bikes = df_weather.merge(counts_with_all, how='inner', on='time')\n",
    "\n",
    "# Indicate the city the columns are from\n",
    "bikes.insert(4, 'city', 'New-York')\n",
    "\n",
    "#pre processing vehicle data\n",
    "df_vh_nyc = df_traffic.copy()\n",
    "df_vh_nyc['Date'] = pd.to_datetime(df_vh_nyc['Date'], format='%Y-%m-%dT%H:%M:%S.%f')\n",
    "df_vh_nyc = df_vh_nyc.drop(['Roadway Name', 'From', 'To', 'Direction'], axis=1)\n",
    "\n",
    "# rename the columns \n",
    "df_vh_nyc.columns = [  'ID','Segment ID', 'date', '0', '1',\n",
    "                       '2', '3', '4', '5',\n",
    "                       '6', '7', '8', '9',\n",
    "                       '10', '11', '12', '13',\n",
    "                       '14', '15', '16', '17',\n",
    "                       '18', '19', '20', '21',\n",
    "                       '22', '23']\n",
    "df_vh_nyc['date'] = pd.to_datetime(df_vh_nyc['date'])\n",
    "\n",
    "# Put hourly count columns in rows of 1 column with name hour. Save all the values into count\n",
    "df_vh_nyc_melt = df_vh_nyc.melt(id_vars = ['date','ID','Segment ID'],\n",
    "                         var_name = 'hour', \n",
    "                         value_name = \"count\").sort_values('date')\n",
    "\n",
    "# We dont have coordinate data for these columns, so we fill them with -9999\n",
    "df_vh_nyc_melt.insert(4, 'latitude', -9999)\n",
    "df_vh_nyc_melt.insert(4, 'longitude', -9999)\n",
    "\n",
    "# Rename columns to fit general format\n",
    "df_vh_nyc_melt.columns = ['time', 'ID', 'Segment ID', 'hour', 'longitude', 'latitude', 'count']\n",
    "\n",
    "# Add weather data\n",
    "df_nyc_traf = df_weather.merge(df_vh_nyc_melt, how='inner', on='time')\n",
    "\n",
    "# Add city column\n",
    "df_nyc_traf.insert(4, 'city', 'New-York')\n",
    "\n",
    "# Add transportation type column\n",
    "df_nyc_traf.insert(4, 'type', 'vehicle')\n",
    "\n",
    "# Select only useful columns in the right order to fit general df\n",
    "df_nyc_traf = df_nyc_traf[['time', 'temp', 'dwpt', 'rhum', 'city', 'wdir', 'wspd', 'pres',\n",
    "       'longitude', 'latitude', 'hour', 'type', 'count', 'ID', 'Segment ID']]\n",
    "\n",
    "# cancatinate bike and traffic data\n",
    "nyc = pd.concat([df_nyc_traf,bikes], axis=0)\n",
    "\n",
    "# Save it into the intermediate file\n",
    "nyc.to_csv('Material/nyc.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34eaacd4",
   "metadata": {},
   "source": [
    "# Concatinate nyc data to all the other cities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d3673f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change order of columns in the general database\n",
    "mighty_df= mighty_df[['time', 'temp', 'dwpt', 'rhum', 'city', 'wdir', 'wspd', 'pres',\n",
    "       'longitude', 'latitude', 'hour', 'type', 'count']]\n",
    "\n",
    "# add New-york data to all data\n",
    "all_df = pd.concat([mighty_df,nyc], axis=0)\n",
    "\n",
    "# Reset index and drop the column\n",
    "all_df = all_df.reset_index()\n",
    "all_df= all_df.drop('index', axis=1)\n",
    "\n",
    "# Save it in the file\n",
    "all_df.to_csv('Material/nyc_cop_lon.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c0a9208",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
